{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. LSTM with Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242990"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw(\"melville-moby_dick.txt\")\n",
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1\r\n",
      "\r\n",
      "Loomings.\r\n",
      "\r\n",
      "\r\n",
      "Call me Ishmael.  Some years ago--never mind how long\r\n",
      "precisely--having little or no money in my purse, and nothing\r\n",
      "particular to interest me on shore, I thought I would sail about a\r\n",
      "little and see the watery part of the world.  It is a way I have of\r\n",
      "driving off the spleen and regulating the circulation.  Whenever I\r\n",
      "find myself growing grim about the mouth; whenever it is a damp,\r\n",
      "drizzly November in my soul; whenever I find myself involuntarily\r\n",
      "pausing before coffin warehouses, and bringing up the rear of every\r\n",
      "funeral I meet; and especially whenever my hypos get such an upper\r\n",
      "hand of me, that it requires a strong moral principle to prevent me\r\n",
      "from deliberately stepping into the street, and methodically knocking\r\n",
      "people's hats off--then, I account it high time to get to sea as soon\r\n",
      "as I can.  This is my substitute for pistol and ball.  With a\r\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\r\n",
      "take to the ship.  There is nothing surprising in this.  If they but\r\n",
      "knew it, almost all \n"
     ]
    }
   ],
   "source": [
    "print(raw[21945:23000])\n",
    "raw = raw[21945:200000]  # 20ë§Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = raw.replace('--', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHAPTER', '1', 'Loomings', '.', 'Call', 'me', 'Ishmael', '.', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHAPTER/NN', '1/CD', 'Loomings/NNP', './.', 'Call/VB', 'me/PRP', 'Ishmael/NNP', './.', 'Some/DT', 'years/NNS', 'ago/RB', 'never/RB', 'mind/VB', 'how/WRB', 'long/JJ', 'precisely/RB', 'having/VBG', 'little/JJ', 'or/CC', 'no/DT', 'money/NN', 'in/IN', 'my/PRP$', 'purse/NN', ',/,', 'and/CC', 'nothing/NN', 'particular/JJ', 'to/TO', 'interest/NN', 'me/PRP', 'on/IN', 'shore/NN', ',/,', 'I/PRP', 'thought/VBD', 'I/PRP', 'would/MD', 'sail/VB', 'about/IN', 'a/DT', 'little/JJ', 'and/CC', 'see/VB', 'the/DT', 'watery/JJ', 'part/NN', 'of/IN', 'the/DT', 'world/NN']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(doc):\n",
    "    return [\"/\".join(p) for p in pos_tag(doc)]\n",
    "\n",
    "tokens = tokenizer(tokens)\n",
    "\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(analyzer = 'word',\n",
    "                           tokenizer=lambda x: x.split(', '),\n",
    "                           preprocessor = None, \n",
    "                           stop_words = None,\n",
    "                           ngram_range=(1, 1),\n",
    "                           lowercase=False\n",
    "                          )\n",
    "\n",
    "data = countvec.fit_transform(tokens).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36630"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['CHAPTER/NN'], dtype='<U26'),\n",
       " array(['1/CD'], dtype='<U26'),\n",
       " array(['Loomings/NNP'], dtype='<U26'),\n",
       " array(['./.'], dtype='<U26'),\n",
       " array(['Call/VB'], dtype='<U26'),\n",
       " array(['me/PRP'], dtype='<U26'),\n",
       " array(['Ishmael/NNP'], dtype='<U26'),\n",
       " array(['./.'], dtype='<U26'),\n",
       " array(['Some/DT'], dtype='<U26'),\n",
       " array(['years/NNS'], dtype='<U26'),\n",
       " array(['ago/RB'], dtype='<U26'),\n",
       " array(['never/RB'], dtype='<U26'),\n",
       " array(['mind/VB'], dtype='<U26'),\n",
       " array(['how/WRB'], dtype='<U26'),\n",
       " array(['long/JJ'], dtype='<U26'),\n",
       " array(['precisely/RB'], dtype='<U26'),\n",
       " array(['having/VBG'], dtype='<U26'),\n",
       " array(['little/JJ'], dtype='<U26'),\n",
       " array(['or/CC'], dtype='<U26'),\n",
       " array(['no/DT'], dtype='<U26'),\n",
       " array(['money/NN'], dtype='<U26'),\n",
       " array(['in/IN'], dtype='<U26'),\n",
       " array(['my/PRP$'], dtype='<U26'),\n",
       " array(['purse/NN'], dtype='<U26'),\n",
       " array([',/,'], dtype='<U26'),\n",
       " array(['and/CC'], dtype='<U26'),\n",
       " array(['nothing/NN'], dtype='<U26'),\n",
       " array(['particular/JJ'], dtype='<U26'),\n",
       " array(['to/TO'], dtype='<U26'),\n",
       " array(['interest/NN'], dtype='<U26')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec.inverse_transform(data)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers, dropout = 0.5)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out, (hidden, cell) = self.lstm(input.view(1,1,-1),(hidden,cell))\n",
    "        out = self.fc(out.view(1,-1))\n",
    "        return out,hidden, cell\n",
    "\n",
    "    def init_hidden_cell(self):\n",
    "        hidden = torch.zeros(self.num_layers, 1, self.hidden_size).cuda()\n",
    "        cell = torch.zeros(self.num_layers, 1, self.hidden_size).cuda()\n",
    "        return hidden, cell\n",
    "\n",
    "    \n",
    "model = LSTM(len(data[0]), 1000, len(data[0]), 2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step = 10\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1000/3661] Loss: 161.2860\n",
      "Epoch [1/10], Iter [2000/3661] Loss: 220.3274\n",
      "Epoch [1/10], Iter [3000/3661] Loss: 199.1042\n",
      "Epoch [2/10], Iter [1000/3661] Loss: 576.1527\n",
      "Epoch [2/10], Iter [2000/3661] Loss: 218.2385\n",
      "Epoch [2/10], Iter [3000/3661] Loss: 410.0923\n",
      "Epoch [3/10], Iter [1000/3661] Loss: 127.4666\n",
      "Epoch [3/10], Iter [2000/3661] Loss: 261.7136\n",
      "Epoch [3/10], Iter [3000/3661] Loss: 641.1652\n",
      "Epoch [4/10], Iter [1000/3661] Loss: 335.1092\n",
      "Epoch [4/10], Iter [2000/3661] Loss: 351.0817\n",
      "Epoch [4/10], Iter [3000/3661] Loss: 289.4716\n",
      "Epoch [5/10], Iter [1000/3661] Loss: 314.1636\n",
      "Epoch [5/10], Iter [2000/3661] Loss: 410.8134\n",
      "Epoch [5/10], Iter [3000/3661] Loss: 540.3054\n",
      "Epoch [6/10], Iter [1000/3661] Loss: 346.7859\n",
      "Epoch [6/10], Iter [2000/3661] Loss: 296.6013\n",
      "Epoch [6/10], Iter [3000/3661] Loss: 282.1308\n",
      "Epoch [7/10], Iter [1000/3661] Loss: 323.8258\n",
      "Epoch [7/10], Iter [2000/3661] Loss: 334.5731\n",
      "Epoch [7/10], Iter [3000/3661] Loss: 166.2658\n",
      "Epoch [8/10], Iter [1000/3661] Loss: 328.7048\n",
      "Epoch [8/10], Iter [2000/3661] Loss: 413.6227\n",
      "Epoch [8/10], Iter [3000/3661] Loss: 383.3750\n",
      "Epoch [9/10], Iter [1000/3661] Loss: 414.3060\n",
      "Epoch [9/10], Iter [2000/3661] Loss: 230.8530\n",
      "Epoch [9/10], Iter [3000/3661] Loss: 520.6946\n",
      "Epoch [10/10], Iter [1000/3661] Loss: 258.5501\n",
      "Epoch [10/10], Iter [2000/3661] Loss: 635.5406\n",
      "Epoch [10/10], Iter [3000/3661] Loss: 527.7526\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sp = list(range(0, len(data) - 2 * step, step))\n",
    "    sp = np.add(sp, random.randint(0, step))\n",
    "    random.shuffle(sp)\n",
    "    \n",
    "    for i in range(len(sp)) :\n",
    "    \n",
    "        (hidden, cell) = model.init_hidden_cell()\n",
    "\n",
    "        cost = 0\n",
    "\n",
    "        for pos in range(sp[i], sp[i] + step):\n",
    "            X = torch.from_numpy(data[pos]).type(torch.FloatTensor).cuda()\n",
    "            y = torch.from_numpy(data[pos+1]).cuda()\n",
    "            _, y = y.max(dim=0)\n",
    "            y = y.unsqueeze(0)\n",
    "\n",
    "            pred, hidden, cell = model(X,hidden,cell)\n",
    "            cost += loss(pred, y.cuda())\n",
    "\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 1000 == 0 :\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'%(epoch+1, num_epochs, i + 1, len(sp), cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial :\n",
    "Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generated Text : \n",
      " me trying off . will income other other will little ; bought quietly an ; but ensued world-wide other the inches lighten morning head ; does Dost have ; ; . ; ; than run ; head ; fact ; ; an will other Seven the he room leaving enough Dost honour than had . than way conscience than but Alone few to driving but but the morning ; does sitting eyes darkened . . ; inches sitting sich relief light ; candelabra-wise towards an other few ; wild ; the than sadly redeemed morning , but has ; have the\n"
     ]
    }
   ],
   "source": [
    "start_num = 5\n",
    "text = countvec.inverse_transform(data[start_num])[0][0].split('/')[0]\n",
    "\n",
    "model.eval()\n",
    "hidden, cell = model.init_hidden_cell()\n",
    "\n",
    "X_test = torch.from_numpy(data[start_num]).type(torch.FloatTensor).cuda()\n",
    "\n",
    "for pos in range(100) :\n",
    "    \n",
    "    pred, hidden, cell = model(X_test, hidden, cell)\n",
    "    \n",
    "    m = torch.nn.Softmax(dim = pred.shape[0])\n",
    "    \n",
    "    pred = m(pred)\n",
    "    \n",
    "    pred = torch.multinomial(pred, 1).data[0][0]\n",
    "    \n",
    "    temp = np.zeros(len(data[0]))\n",
    "    \n",
    "    temp[pred] = 1\n",
    "    \n",
    "    text += \" \" + countvec.inverse_transform(temp)[0][0].split('/')[0]\n",
    "    \n",
    "    X_test = torch.from_numpy(temp).type(torch.FloatTensor).cuda()\n",
    "    \n",
    "print(\"* Generated Text : \\n\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
